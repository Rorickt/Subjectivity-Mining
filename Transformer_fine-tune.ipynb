{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1femEOc0AVv9eZPqIw-7Qt0deaApVUHQw","authorship_tag":"ABX9TyMAGUIVhad4SMtaG9+nuf1Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"168n8xopZawa","executionInfo":{"status":"ok","timestamp":1665492022892,"user_tz":-120,"elapsed":41585,"user":{"displayName":"Rorick .Terlou","userId":"03994060267262898423"}}},"outputs":[],"source":["# to supress the output here\n","%%capture \n","\n","# install prerequisites\n","!pip install simpletransformers\n","!pip install sentence_transformers"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fIiN2NWcdN2w","executionInfo":{"status":"ok","timestamp":1665492094267,"user_tz":-120,"elapsed":71383,"user":{"displayName":"Rorick .Terlou","userId":"03994060267262898423"}},"outputId":"59c315c1-d83a-4e3c-c074-5bae473bf5eb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd, numpy as np\n","import sklearn\n","import seaborn as sns\n","\n","from simpletransformers.classification import ClassificationModel, ClassificationArgs\n","from sklearn.metrics import classification_report, confusion_matrix"],"metadata":{"id":"z6NNJ2LEcKtb","executionInfo":{"status":"ok","timestamp":1665492101618,"user_tz":-120,"elapsed":7364,"user":{"displayName":"Rorick .Terlou","userId":"03994060267262898423"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Prerequisites:\n","\n","The cell below allows the user to specify which transformer model they need to run and whre the data is located. \\\n","The user should also select which training data to use for either in-domain or cross-domain testing."],"metadata":{"id":"6XWvobSzdD97"}},{"cell_type":"code","source":["# set the correct model (should already be good but choose from: \"diptanu/fBERT\", \"bert-base-uncased\")\n","model_name = \"bert-base-uncased\"\n","domain = 'cross' # or select 'in'\n","\n","# set here the folder that contains the data folder (which in turn contains all the required datasets)\n","dir = '/content/drive/MyDrive/subjectivity_mining/'\n"],"metadata":{"id":"nJBuvjoci4F9","executionInfo":{"status":"ok","timestamp":1665493669910,"user_tz":-120,"elapsed":446,"user":{"displayName":"Rorick .Terlou","userId":"03994060267262898423"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["if domain == 'cross':\n","    # cross domain HASOC data\n","    train_df = pd.read_csv(f'{dir}data/hasoc-train-small.csv') # for fine-tuning\n","    dev_df = pd.read_csv(f'{dir}data/hasoc-dev.csv') # for fine-tuning\n","    full_train_df = pd.read_csv(f'{dir}data/hasoc-train-all.csv')\n","else:\n","    # indomain OLID data\n","    train_df = pd.read_csv(f'{dir}data/olid-train-small.csv') # for fine-tuning\n","    dev_df = pd.read_csv(f'{dir}data/olid-dev.csv') # for fine-tuning\n","    full_train_df = pd.read_csv(f'{dir}data/olid-train-all.csv')\n","\n","# general test data\n","test_df = pd.read_csv(f'{dir}data/olid-test.csv')\n","# where to store the final model and intermediate results\n","save_dir = f'{dir}outputs/' "],"metadata":{"id":"bWw5Vw6IfLJk","executionInfo":{"status":"ok","timestamp":1665493671321,"user_tz":-120,"elapsed":3,"user":{"displayName":"Rorick .Terlou","userId":"03994060267262898423"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Fine-tuning\n","\n","The cell below runs the fine-tuning of the models.\\\n","As of yet, only learning rate is adjusted however, to avoid running unneccesarily long epoch, we set an early stopping parameter. This will avoid our model from over training when the performance is contiunuously decreasing.\n","\n","A manual seed is set. This is done to avoid having to do many iterations to acocunt for the stochastic nature of deep learning models. We are constrain by time and a faster option is to only use one seed. The seed was not specifically selected for its perfomance.\n","\n","During this setup, only the final model is saved (however not used).\n","The outcome is shown in the cell below using MCC scores. The highest performing model is used for the final model's training"],"metadata":{"id":"BQFZilHHdJU8"}},{"cell_type":"code","source":["# hyperparameter tuning\n","# run this cell and after its done the next cell. This will take a while (15-30 minutes)\n","learning_rates = [2e-5, 3e-5, 4e-5]\n","\n","\n","for lr in learning_rates:\n","    model_args = {\n","      'max_seq_length': 64,\n","      'train_batch_size': 8,\n","      'eval_batch_size': 8,\n","      'num_train_epochs': 5,\n","      'learning_rate': lr,\n","      'adam_epsilon': 1e-8,\n","      'output_dir': f'{save_dir}/temp_{model_name}_{domain}_model_{lr}',\n","      'overwrite_output_dir': True,\n","      'manual_seed': 123,\n","      'use_early_stopping': True,\n","      'evaluate_during_training': True,\n","      'evaluate_during_training_verbose': True,\n","      'save_model_every_epoch': False,\n","      'save_steps': -1,\n","      'no_save': True\n","    }\n","    # Train the model\n","    model = ClassificationModel(\"bert\", model_name, args=model_args, use_cuda=True)\n","    model.train_model(train_df, eval_df=dev_df)\n","\n","    # Evaluate the model\n","    result, model_outputs, wrong_predictions = model.eval_model(dev_df)\n"],"metadata":{"id":"TX9Pfr4esXJ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pick best performing model for final training (highest MCC score)\n","full_results = pd.DataFrame()\n","for lr in [2e-5, 3e-5, 4e-5]:\n","    partial_result = pd.read_csv(f'{save_dir}/temp_{model_name}_model_{lr}/training_progress_scores.csv')\n","    partial_result = partial_result[partial_result.global_step != 2000]\n","    partial_result['Learning Rate'] = str(lr)\n","    partial_result['Epochs'] = np.arange(len(partial_result))\n","    full_results = pd.concat([full_results, partial_result])\n","\n","full_results.reset_index(inplace=True)\n","\n","sns.set_theme(style=\"darkgrid\")\n","# Plot the f-score per epoch for the different number of hidden nodes\n","sns.relplot(x=\"Epochs\", y=\"mcc\", data=full_results, hue='Learning Rate', \n","            ci=None, marker='o', palette='bright', kind=\"line\"\n","            )"],"metadata":{"id":"iXBGQHb5vv05"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Final model training and storing\n","\n","The final section  of the code fine-tunes the model with the full training data and stores the resulting model on the drive.\\\n","It also shows the classification report and confusion matrix using the final test data."],"metadata":{"id":"oWBwhT89fQrQ"}},{"cell_type":"code","source":["# set correct parameters based on highest perfomring model above (set #epochs and learning rate)\n","model_args = {\n","      'max_seq_length': 64,\n","      'train_batch_size': 8,\n","      'eval_batch_size': 8,\n","      'num_train_epochs': 2,  # <------------- SET THIS CORRECTLY \n","      'learning_rate': 4e-5,  # <------------- SET THIS CORRECTLY\n","      'adam_epsilon': 1e-8,\n","      'output_dir': f'{save_dir}/final_{model_name}_{domain}_model',\n","      'overwrite_output_dir': True,\n","      'manual_seed': 123,\n","      'save_model_every_epoch': False,\n","      'save_steps': -1\n","    }\n","# Train the model\n","model = ClassificationModel(\"bert\", model_name, args=model_args, use_cuda=True)\n","model.train_model(full_train_df)\n","\n","# Evaluate the model\n","result, model_outputs, wrong_predictions = model.eval_model(test_df)\n","\n","# Make predictions with the model\n","predictions, raw_outputs = model.predict(list(test_df.text))\n","print(classification_report(test_df.labels, predictions))"],"metadata":{"id":"aYR83DkN4t47"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["confusion_matrix(test_df.labels, predictions)"],"metadata":{"id":"UvpQ_JbNqNUp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EgrxOYh2rLyq"},"execution_count":null,"outputs":[]}]}